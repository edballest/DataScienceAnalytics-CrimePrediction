{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be using Intel's distribution of python for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.3 |Intel Corporation| (default, Oct 17 2017, 23:26:12) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==0.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash.exe: warning: could not find /tmp, please create!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#check scikit-learn version\n",
    "pip freeze | grep scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1993, 104)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('Data/communities-crime-clean.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn need all attributes to be numeric. Let's check the data types to be sure there are no non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    101\n",
       "int64        2\n",
       "object       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check column types\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state             int64\n",
       "communityname    object\n",
       "fold              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes[data.dtypes != float]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only columns with non - numeric data type is \"communityname\". This column won't be used in the model so this is not a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tCreate a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. What are the percentage of positive and negative instances in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create highCrime field\n",
    "data['highCrime'] = data['ViolentCrimesPerPop'].apply(lambda x: int(x>0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62719518314099343"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['highCrime'])/len(data['highCrime']) #percentage of positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Use DecisionTreeClassifier to learn a decision tree to predict highCrime on the entire dataset. Remember to exclude the crime rate feature (ViolentCrimesPerPop) from the input feature set so you are not cheating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove non predictive attributes (comunityname,fold), ViolentCrimesPerPop (avoid cheating) and the target (highCrime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create X,y variables\n",
    "X = pd.DataFrame.drop(data,['communityname','fold','ViolentCrimesPerPop','highCrime'],axis=1) #predictors\n",
    "y = data.highCrime #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 101)\n",
      "(1993,)\n"
     ]
    }
   ],
   "source": [
    "#check dimensions\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import DecisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train decision tree\n",
    "dTree = DecisionTreeClassifier()\n",
    "dTree.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tWhat are the training accuracy, precision, and recall for this tree? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function\n",
    "def trainScores(yTrue,yPred, printResults=True):\n",
    "    '''Returns cross validation accuracy,precision and recall for model'''\n",
    "    accuracy = metrics.accuracy_score(yTrue,yPred)\n",
    "    precision = metrics.precision_score(yTrue,yPred)\n",
    "    recall  = metrics.recall_score(yTrue,yPred)\n",
    "    if printResults:\n",
    "        print('Accuracy: ' + str(accuracy))\n",
    "        print('Precision: ' + str(precision))\n",
    "        print('Recall: ' + str(recall))\n",
    "    return accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training data\n",
    "yPred = dTree.predict(X)\n",
    "accuracy,precision,recall = trainScores(y,yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat are the main features used for classification? Can you explain why they make sense (or not)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.358652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.089501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.048585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PctEmplManu</td>\n",
       "      <td>0.020022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PctLess9thGrade</td>\n",
       "      <td>0.018634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "45      PctKids2Par    0.358652\n",
       "4      racePctWhite    0.089501\n",
       "6       racePctHisp    0.048585\n",
       "35      PctEmplManu    0.020022\n",
       "30  PctLess9thGrade    0.018634"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asses feature importance\n",
    "f_importance = pd.DataFrame(list(zip(X.columns,dTree.feature_importances_)))\n",
    "f_importance.columns = ['feature','importance']\n",
    "f_importance.sort_values(by=['importance'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is nearly impossible to establish any kind of causality since so many of the features are highly correlated. The most relevant parameter is the percentage of kids in family housing with two parents. The second and third most relevant parameters are race related, and the 4th and 5th are employment related. It makes sense that these parameters are good predictor, but as discussed before it would be difficult to establish any kind of causal relationship since all of them are going to be highly correlated with for example income and level of education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\tNow apply cross-validation (cross_val_score) to do 10-fold cross-validation to estimate the out-of-training accuracy of decision tree learning for this task\n",
    "**i.\tWhat are the 10-fold cross-validation accuracy, precision, and recall?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function\n",
    "def crossValidationScores(model,X,y,cv_folds = 10, printResults=True):\n",
    "    '''Returns cross validation accuracy,precision and recall for model'''\n",
    "    kf = KFold(n_splits=cv_folds,random_state=1914) #set random_state to obtain repeatable results\n",
    "    \n",
    "    accuracy = cross_val_score(model,X,y,cv=kf,scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model,X,y,cv=kf,scoring='precision').mean()\n",
    "    recall  = cross_val_score(model,X,y,cv=kf,scoring='recall').mean()\n",
    "    \n",
    "    if printResults:\n",
    "        print('Accuracy: ' + str(accuracy))\n",
    "        print('Precision: ' + str(precision))\n",
    "        print('Recall: ' + str(recall))\n",
    "    \n",
    "    return accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.753535175879\n",
      "Precision: 0.795084732277\n",
      "Recall: 0.784294231497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score #stratified by default\n",
    "dTree = DecisionTreeClassifier()\n",
    "accuracy,precision,recall = crossValidationScores(dTree,X,y)\n",
    "allScores = pd.DataFrame(data = {'Accuracy': accuracy,'Precision': precision,'Recall': recall},\n",
    "                         index=['Decision Tree']) #to compate with othe models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhy are they different from the results in the previous test?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The huge difference between the results before and the results out of sample suggest overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tUse GaussianNB to learn a Naive Bayes classifier to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tWhat is the 10-fold cross-validation accuracy, precision, and recall for this method?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.768153266332\n",
      "Precision: 0.901253562112\n",
      "Recall: 0.684065991577\n"
     ]
    }
   ],
   "source": [
    "gNB = GaussianNB()\n",
    "accuracy,precision,recall = crossValidationScores(gNB,X,y)\n",
    "gNBscores = pd.DataFrame(data = {'Accuracy': accuracy,'Precision': precision,'Recall': recall},\n",
    "                         index=['Gaussian NB']) #to compate with othe models\n",
    "allScores = allScores.append(gNBscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat are the 10 most predictive features? Why do these make sense (or not)? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gNB.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the normalized absolute difference of means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_T, theta_F = gNB.theta_\n",
    "sigma_T, sigma_F = gNB.sigma_\n",
    "NADMs = abs(theta_T-theta_F)/(sigma_T+sigma_F) #normalized absolute difference of means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>NADM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>5.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FemalePctDiv</td>\n",
       "      <td>4.756826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctFam2Par</td>\n",
       "      <td>4.593940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>4.394939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>4.385936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PctTeen2Par</td>\n",
       "      <td>3.999311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>3.950688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PctYoungKids2Par</td>\n",
       "      <td>3.648270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>PctIlleg</td>\n",
       "      <td>3.469861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>3.443203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature      NADM\n",
       "45       PctKids2Par  5.001257\n",
       "41      FemalePctDiv  4.756826\n",
       "44        PctFam2Par  4.593940\n",
       "16        pctWInvInc  4.394939\n",
       "42       TotalPctDiv  4.385936\n",
       "47       PctTeen2Par  3.999311\n",
       "39    MalePctDivorce  3.950688\n",
       "46  PctYoungKids2Par  3.648270\n",
       "51          PctIlleg  3.469861\n",
       "4       racePctWhite  3.443203"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_importance = pd.DataFrame(list(zip(X.columns,NADMs)))\n",
    "f_importance.columns = ['feature','NADM']\n",
    "f_importance.sort_values(by=['NADM'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most predictive variables are:\n",
    "1. Percentage of kids in family housing with two parents. \n",
    "2. Percentage of females who are divorced.\n",
    "3. Percentage of families (with kids) that are headed by two parents.\n",
    "4. Percentage of households with investment / rent income in 1989.\n",
    "5. Percentage of population who are divorced.\n",
    "6. Percent of kids age 12-17 in two parent households.\n",
    "7. Percentage of males who are divorced.\n",
    "8. Percent of kids 4 and under in two parent households\n",
    "9. Percentage of kids born to never married \n",
    "10. Percentage of population that is caucasian.\n",
    "\n",
    "Most of the predictive variables seem to be related to kids and their parents marital status. Two possible hypothesis would be that kids with divorced parents tend to incur in criminal activity more often or that families with kids are more likely to report crimes near their household."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii.\tHow do these results compare with your results from decision trees, above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.753535</td>\n",
       "      <td>0.795085</td>\n",
       "      <td>0.784294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB</th>\n",
       "      <td>0.768153</td>\n",
       "      <td>0.901254</td>\n",
       "      <td>0.684066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision    Recall\n",
       "Decision Tree  0.753535   0.795085  0.784294\n",
       "Gaussian NB    0.768153   0.901254  0.684066"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and Precision have been improved. Recall reduced.\n",
    "Regarding the importance of the features, in both models \"Percentage of kids in family housing with two parents\" turns out to be the most important variable. \"racePctWhite\" appears in the two models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tUse LinearSVC to learn a linear Support Vector Machine model to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the 10-fold cross-validation accuracy, precision, and recall for this method?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.779090452261\n",
      "Precision: 0.812613824957\n",
      "Recall: 0.834368433197\n"
     ]
    }
   ],
   "source": [
    "lSVC = LinearSVC()\n",
    "accuracy,precision,recall = crossValidationScores(lSVC,X,y)\n",
    "lSVCscores = pd.DataFrame(data = {'Accuracy': accuracy,'Precision': precision,'Recall': recall},\n",
    "                         index=['Linear SVC']) #to compate with othe models\n",
    "allScores = allScores.append(lSVCscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat are the 10 most predictive features? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lSVC.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>0.924282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RentHighQ</td>\n",
       "      <td>0.902167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>0.858574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.840028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>HousVacant</td>\n",
       "      <td>0.815141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>agePct12t21</td>\n",
       "      <td>0.811858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>PctPersDenseHous</td>\n",
       "      <td>0.799961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NumUnderPov</td>\n",
       "      <td>0.739350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PctOccupMgmtProf</td>\n",
       "      <td>0.726710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racepctblack</td>\n",
       "      <td>0.671560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficient\n",
       "65  PersPerOccupHous     0.924282\n",
       "85         RentHighQ     0.902167\n",
       "39    MalePctDivorce     0.858574\n",
       "6        racePctHisp     0.840028\n",
       "72        HousVacant     0.815141\n",
       "7        agePct12t21     0.811858\n",
       "69  PctPersDenseHous     0.799961\n",
       "28       NumUnderPov     0.739350\n",
       "38  PctOccupMgmtProf     0.726710\n",
       "3       racepctblack     0.671560"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asses feature importance\n",
    "f_importance = pd.DataFrame(list(zip(X.columns,lSVC.coef_[0]))) #lSVC.coef_ retunts a list o a list of the coefs\n",
    "f_importance.columns = ['feature','coefficient']\n",
    "f_importance.sort_values(by=['coefficient'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most predictive variables are:\n",
    "1. Mean persons per household. \n",
    "2. Rental housing - upper quartile rent.\n",
    "3. Percentage of males who are divorced.\n",
    "4. Percentage of population that is of hispanic heritage.\n",
    "5. Number of vacant households.\n",
    "6. Percentage of population that is 12-21 in age.\n",
    "7. Percent of persons in dense housing.\n",
    "8. Percentage of people 16 and over who are employed in management or professional occupations.\n",
    "9. Number of people under the poverty level.\n",
    "10. Percentage of population that is african american.\n",
    "\n",
    "As seen also in other results, parameters related to income-level, sex and marital status seem to be the best predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii.\tHow do these results compare with your results from decision trees, above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.753535</td>\n",
       "      <td>0.795085</td>\n",
       "      <td>0.784294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB</th>\n",
       "      <td>0.768153</td>\n",
       "      <td>0.901254</td>\n",
       "      <td>0.684066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.779090</td>\n",
       "      <td>0.812614</td>\n",
       "      <td>0.834368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision    Recall\n",
       "Decision Tree  0.753535   0.795085  0.784294\n",
       "Gaussian NB    0.768153   0.901254  0.684066\n",
       "Linear SVC     0.779090   0.812614  0.834368"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Naive Bayes classifier, Accuracy and Precision have been improved and Recall reduced. The difference is Precision has been improved less but reclass has been reduced less as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we need to remove nonpredictive attributes (comunitynamefold),  and the target (ViolentCrimesPerPop). We continue to remove highCrime since we introduced it from ViolentCrimesPerProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create X,y variables\n",
    "X = pd.DataFrame.drop(data,['communityname','fold','ViolentCrimesPerPop','highCrime'],axis=1) #predictors\n",
    "y = data.ViolentCrimesPerPop #target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tUse LinearRegression to learn a linear model directly predicting the crime rate per capita (ViolentCrimesPerPop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tUsing 10-fold cross-validation, what is the estimated mean-squared-error (MSE) of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function\n",
    "def crossValidationMSE(model, X, y, cv = 10, printResults=True):\n",
    "    '''Returns cross validation MSE for model'''\n",
    "    kf = KFold(n_splits=cv,random_state=1914) #set random_state to obtain repeatable results\n",
    "    \n",
    "    cvMSE = -cross_val_score(model,X,y,cv=kf,scoring='neg_mean_squared_error').mean()\n",
    "    if printResults:\n",
    "        print('cross-validation MSE: ' + str(MSE))\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MSE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0b4b3ec8939a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlinReg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcvMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossValidationMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinReg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-4874d416487e>\u001b[0m in \u001b[0;36mcrossValidationMSE\u001b[1;34m(model, X, y, cv, printResults)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcvMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprintResults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cross-validation MSE: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MSE' is not defined"
     ]
    }
   ],
   "source": [
    "linReg = LinearRegression()\n",
    "cvMSE = crossValidationMSE(linReg,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat is the MSE on the training set (train on all the data then test on it all)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function\n",
    "def trainMSE(yTrue,yPred, printResults=True):\n",
    "    '''Returns model's MSE on train data'''\n",
    "    MSE = metrics.mean_squared_error(yTrue,yPred)\n",
    "    if printResults:\n",
    "        print('train MSE: '  + str(MSE))\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linReg.fit(X,y)\n",
    "yPred = linReg.predict(X)\n",
    "tMSE = trainMSE(y,yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii.\tWhat features are most predictive of a high crime rate? A low crime rate?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(list(zip(X.columns,linReg.coef_))) #lSVC.coef_ retunts a list o a list of the coefs\n",
    "coefficients.columns = ['feature','coefficient']\n",
    "sorted_coefficients = coefficients.sort_values(by=['coefficient'],ascending=False)\n",
    "sorted_coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_coefficients.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Positive Coefficients:\n",
    "1. Percent of households owner occupied.\n",
    "2. Mean persons per household.\n",
    "3. Percentage of males who are divorced.\n",
    "4. Percent of _population_ who have immigrated within the last 8 years.\n",
    "5. Median gross rent.\n",
    "\n",
    "Most Negative Coefficients: (most negative to less negative)\n",
    "1. Percent of people in owner occupied households.\n",
    "2. Percentage of population who are divorced.\n",
    "3. Owner occupied housing - lower quartile value.\n",
    "4. Per capita income for caucasians.\n",
    "5. Percentage of kids in family housing with two parents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tNow use Ridge regression to reduce the amount of overfitting, pick the best alpha from among (10, 1, 0.1, 0.01, and 0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "rReg = RidgeCV(alphas=(10, 1, 0.1, 0.01, 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tWhat is the estimated MSE of the model under 10-fold CV?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = crossValidationMSE(rReg,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat is the MSE on the training set (train on all the data then test on it all)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rReg.fit(X,y)\n",
    "yPred = rReg.predict(X)\n",
    "MSE = trainMSE(y,yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii.\tWhat is the best alpha?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rReg.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iv.\tWhat does this say about the amount of overfitting in linear regression for this problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was not too much overfitting on the original linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\tNow use polynomial features to do quadratic (second-order) polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_ = poly.fit_transform(X)\n",
    "linReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tWhat is the estimated MSE of the model under 10-fold CV?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvMSE = crossValidationMSE(linReg,X_,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat is the MSE on the training set (train on all the data then test on it all)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linReg.fit(X_,y)\n",
    "yPred = linReg.predict(X_)\n",
    "tMSE = trainMSE(y,yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii.\tDoes this mean the quadratic model is better than the linear model for this problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. The train MSE is almost 0, so it is possible we are overfitting, but either way the cross-validation MSE is better so we expect this model to perfor better out of sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirty Data\n",
    "Load and check dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('Data/communities-crime-full.csv',na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data now has 1994 rows and 128 columns (the clean one had 1993 rows and 104 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_NaNs = data.apply(lambda x: sum(x.isnull()),axis=0) \n",
    "n_NaNs [n_NaNs != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like in the clean data all these columns (except OtherPerCap) where deleted, as well as the row with the missing OtherPerCap value. Let's try mean value imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missingFeatures_series = n_NaNs [n_NaNs != 0]\n",
    "missingFeatures = list(missingFeatures_series.index)\n",
    "for f in missingFeatures:\n",
    "    data[f].fillna(data[f].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check no NaNs remaining\n",
    "data.isnull().any().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat the decision tree learning question for the full (non-clean) data set and present the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create highCrime field\n",
    "data['highCrime'] = data['ViolentCrimesPerPop'].apply(lambda x: int(x>0.1))\n",
    "\n",
    "#Create X,y variables\n",
    "X = pd.DataFrame.drop(data,['communityname','fold','ViolentCrimesPerPop','highCrime'],axis=1) #predictors\n",
    "y = data.highCrime #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model and measure performance\n",
    "dTree = DecisionTreeClassifier()\n",
    "\n",
    "print('cross validation')\n",
    "accuracy,precision,recall = crossValidationScores(dTree,X,y)\n",
    "\n",
    "dTree.fit(X,y)\n",
    "yPred = dTree.predict(X)\n",
    "\n",
    "print('\\nTrain')\n",
    "tMSE = trainScores(y,yPred)\n",
    "\n",
    "dirtyScores = pd.DataFrame(data = {'Accuracy': accuracy,'Precision': precision,'Recall': recall},\n",
    "                         index=['Dirty Decision Tree']) #to compate with othe models\n",
    "allScores = allScores.append(dirtyScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Are the CV results better or worse? What does this say about the effect of missing values?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though mean value imputation is not the best possible method, the results improve slightly, which means the some eliminated columns contained valuable information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
