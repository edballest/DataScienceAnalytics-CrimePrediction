{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be using Intel's release of python for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.3 |Intel Corporation| (default, Oct 17 2017, 23:26:12) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==0.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash.exe: warning: could not find /tmp, please create!\n",
      "You are using pip version 9.0.1, however version 9.0.3 is available.\r\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep scikit-learn #check scikit-learn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tCreate a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. What are the percentage of positive and negative instances in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('Data/communities-crime-clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create highCrime field\n",
    "data['highCrime'] = data['ViolentCrimesPerPop'].apply(lambda x: int(x>0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62719518314099343"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['highCrime'])/len(data['highCrime']) #percentage of positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Use DecisionTreeClassifier to learn a decision tree to predict highCrime on the entire dataset. Remember to exclude the crime rate feature (ViolentCrimesPerPop) from the input feature set so you are not cheating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove non predictive attributes (comunityname,fold), ViolentCrimesPerPop (avoid cheating) and the target (highCrime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X,y variables\n",
    "X = pd.DataFrame.drop(data,['communityname','fold','ViolentCrimesPerPop','highCrime'],axis=1) #predictors\n",
    "y = data.highCrime #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 101)\n",
      "(1993,)\n"
     ]
    }
   ],
   "source": [
    "#check dimensions\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import DecisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train decision tree\n",
    "dTree = DecisionTreeClassifier()\n",
    "dTree.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tWhat are the training accuracy, precision, and recall for this tree? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precission: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training data\n",
    "from sklearn import metrics\n",
    "yPred = dTree.predict(X)\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y,yPred)))\n",
    "print('Precission: ' + str(metrics.precision_score(y,yPred)))\n",
    "print('Recall: ' + str(metrics.recall_score(y,yPred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat are the main features used for classification? Can you explain why they make sense (or not)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.358652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.088817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.045120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PctEmplManu</td>\n",
       "      <td>0.021453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PctEmploy</td>\n",
       "      <td>0.018172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "45   PctKids2Par    0.358652\n",
       "4   racePctWhite    0.088817\n",
       "6    racePctHisp    0.045120\n",
       "35   PctEmplManu    0.021453\n",
       "34     PctEmploy    0.018172"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asses feature importance\n",
    "f_importance = pd.DataFrame(list(zip(X.columns,dTree.feature_importances_)))\n",
    "f_importance.columns = ['feature','importance']\n",
    "f_importance.sort_values(by=['importance'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is nearly impossible to stablish any kind of causality since so many of the features are highly correlated.\n",
    "The most relevant parameter is percentage of kids in family housing with two parents. The second and third most relevant parameters are race related, and the 4th and 5th are employment related. Im makes sense that this parameters are good predictor, but as duscussed before it would be difficult to stablish any kind of causal relationship since all of them are going to be highly correlated with for example income and level of education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\tNow apply cross-validation (cross_val_score) to do 10-fold cross-validation to estimate the out-of-training accuracy of decision tree learning for this task\n",
    "**i.\tWhat are the 10-fold cross-validation accuracy, precision, and recall?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.718\n",
      "Precission: 0.782714486199\n",
      "Recall: 0.7776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score #stratified by default\n",
    "dTree = DecisionTreeClassifier()\n",
    "accuracy = cross_val_score(dTree,X,y,cv=10,scoring='accuracy').mean()\n",
    "precision = cross_val_score(dTree,X,y,cv=10,scoring='precision').mean()\n",
    "recall  = cross_val_score(dTree,X,y,cv=10,scoring='recall').mean()\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precission: ' + str(precision))\n",
    "print('Recall: ' + str(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhy are they different from the results in the previous test?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The huge difference between the results before and the results out of sample sugest overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
