{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be using Intel's release of python for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.3 |Intel Corporation| (default, Oct 17 2017, 23:26:12) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==0.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash.exe: warning: could not find /tmp, please create!\n",
      "You are using pip version 9.0.1, however version 9.0.3 is available.\r\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep scikit-learn #check scikit-learn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tCreate a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. What are the percentage of positive and negative instances in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('Data/communities-crime-clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create highCrime field\n",
    "data['highCrime'] = data['ViolentCrimesPerPop'].apply(lambda x: int(x>0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62719518314099343"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['highCrime'])/len(data['highCrime']) #percentage of positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Use DecisionTreeClassifier to learn a decision tree to predict highCrime on the entire dataset. Remember to exclude the crime rate feature (ViolentCrimesPerPop) from the input feature set so you are not cheating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove non predictive attributes (comunityname,fold), ViolentCrimesPerPop (avoid cheating) and the target (highCrime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X,y variables\n",
    "X = pd.DataFrame.drop(data,['communityname','fold','ViolentCrimesPerPop','highCrime'],axis=1) #predictors\n",
    "y = data.highCrime #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 101)\n",
      "(1993,)\n"
     ]
    }
   ],
   "source": [
    "#check dimensions\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import DecisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train decision tree\n",
    "dTree = DecisionTreeClassifier()\n",
    "dTree.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tWhat are the training accuracy, precision, and recall for this tree? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precission: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training data\n",
    "from sklearn import metrics\n",
    "yPred = dTree.predict(X)\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y,yPred)))\n",
    "print('Precission: ' + str(metrics.precision_score(y,yPred)))\n",
    "print('Recall: ' + str(metrics.recall_score(y,yPred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat are the main features used for classification? Can you explain why they make sense (or not)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.358652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.088817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.045120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PctEmplManu</td>\n",
       "      <td>0.021453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PctEmploy</td>\n",
       "      <td>0.018172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "45   PctKids2Par    0.358652\n",
       "4   racePctWhite    0.088817\n",
       "6    racePctHisp    0.045120\n",
       "35   PctEmplManu    0.021453\n",
       "34     PctEmploy    0.018172"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asses feature importance\n",
    "f_importance = pd.DataFrame(list(zip(X.columns,dTree.feature_importances_)))\n",
    "f_importance.columns = ['feature','importance']\n",
    "f_importance.sort_values(by=['importance'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is nearly impossible to stablish any kind of causality since so many of the features are highly correlated.\n",
    "The most relevant parameter is percentage of kids in family housing with two parents. The second and third most relevant parameters are race related, and the 4th and 5th are employment related. Im makes sense that this parameters are good predictor, but as duscussed before it would be difficult to stablish any kind of causal relationship since all of them are going to be highly correlated with for example income and level of education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\tNow apply cross-validation (cross_val_score) to do 10-fold cross-validation to estimate the out-of-training accuracy of decision tree learning for this task\n",
    "**i.\tWhat are the 10-fold cross-validation accuracy, precision, and recall?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function\n",
    "def crossValidationScores(model,cv = 10, printResults=True):\n",
    "    '''Returns cross validation accuracy,precission and recall for model'''\n",
    "    accuracy = cross_val_score(model,X,y,cv=10,scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model,X,y,cv=10,scoring='precision').mean()\n",
    "    recall  = cross_val_score(model,X,y,cv=10,scoring='recall').mean()\n",
    "    if printResults:\n",
    "        print('Accuracy: ' + str(accuracy))\n",
    "        print('Precission: ' + str(precision))\n",
    "        print('Recall: ' + str(recall))\n",
    "    return accuracy,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714984924623\n",
      "Precission: 0.776228635597\n",
      "Recall: 0.7816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score #stratified by default\n",
    "dTree = DecisionTreeClassifier()\n",
    "accuracy,precision,recall = crossValidationScores(dTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhy are they different from the results in the previous test?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The huge difference between the results before and the results out of sample sugest overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tUse GaussianNB to learn a Naive Bayes classifier to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i.\tWhat is the 10-fold cross-validation accuracy, precision, and recall for this method?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.765108040201\n",
      "Precission: 0.912419309104\n",
      "Recall: 0.6976\n"
     ]
    }
   ],
   "source": [
    "gNB = GaussianNB()\n",
    "accuracy,precision,recall = crossValidationScores(gNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat are the 10 most predictive features? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper class\n",
    "class normalizedAbsoluteMeansDifference(object):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.nu_y = self.y.mean()\n",
    "        self.sd_y = np.sqrt(self.y.var())\n",
    "        self.df = self.dfNAMD()\n",
    "    def featureNAMD(self,f):\n",
    "        '''computes normalized absolute difference for one feature f'''\n",
    "        x = X[f]\n",
    "        nu_x = x.mean()\n",
    "        sd_x = np.sqrt(x.var())       \n",
    "        return (abs(self.nu_y-nu_x)/(self.sd_y+sd_x))\n",
    "    def dfNAMD(self):\n",
    "        '''computes normalized absolute difference for a whole dataFrame'''\n",
    "        nu_y = y.mean()\n",
    "        sd_y = np.sqrt(y.var())\n",
    "        dfNAMD = pd.DataFrame(X.columns, columns = ['feature'])\n",
    "        dfNAMD['value'] = dfNAMD['feature'].apply(self.featureNAMD)\n",
    "        return dfNAMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state</td>\n",
       "      <td>1.661602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NumImmig</td>\n",
       "      <td>1.045962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>NumStreet</td>\n",
       "      <td>1.034770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>NumInShelters</td>\n",
       "      <td>1.019511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NumIlleg</td>\n",
       "      <td>0.997523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature     value\n",
       "0           state  1.661602\n",
       "52       NumImmig  1.045962\n",
       "91      NumStreet  1.034770\n",
       "90  NumInShelters  1.019511\n",
       "50       NumIlleg  0.997523"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute normalized Absolute Means Difference\n",
    "NAMD = normalizedAbsoluteMeansDifference(X,y)\n",
    "NAMD.df.sort_values(by=['value'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most predictive variables are:\n",
    "1. Stare. \n",
    "2. Number of people known to be foreign born.\n",
    "3. Number of homeless people counted in the street.\n",
    "4. Number of people in homeless shelters.\n",
    "5. Number of kids born to never married\n",
    "\n",
    "Most of the seem to be linked with poverty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii.\tHow do these results compare with your results from decision trees, above?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precission has been improved. Accuracy slightly reduced. Recall greatly reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tUse LinearSVC to learn a linear Support Vector Machine model to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the 10-fold cross-validation accuracy, precision, and recall for this method?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.768138190955\n",
      "Precission: 0.831503504277\n",
      "Recall: 0.7472\n"
     ]
    }
   ],
   "source": [
    "lSVC = LinearSVC()\n",
    "accuracy,precision,recall = crossValidationScores(lSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.\tWhat are the 10 most predictive features? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lSVC.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>0.938564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RentHighQ</td>\n",
       "      <td>0.911587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>0.865824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.853696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>HousVacant</td>\n",
       "      <td>0.813112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficient\n",
       "65  PersPerOccupHous     0.938564\n",
       "85         RentHighQ     0.911587\n",
       "39    MalePctDivorce     0.865824\n",
       "6        racePctHisp     0.853696\n",
       "72        HousVacant     0.813112"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asses feature importance\n",
    "f_importance = pd.DataFrame(list(zip(X.columns,lSVC.coef_[0]))) #lSVC.coef_ retunts a list o a list of the coefs\n",
    "f_importance.columns = ['feature','coefficient']\n",
    "f_importance.sort_values(by=['coefficient'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most predictive variables are:\n",
    "1. Mean persons per household. \n",
    "2. Rental housing - upper quartile rent.\n",
    "3. percentage of males who are divorced.\n",
    "4. percentage of population that is of hispanic heritage.\n",
    "5. Number of vacant households\n",
    "\n",
    "This look way more dispair than the previous ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii.\tHow do these results compare with your results from decision trees, above?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better accuracy and precision. Worst recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
